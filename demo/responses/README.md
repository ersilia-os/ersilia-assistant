This folder contains the responses from the assistant given the inputs in inputs.py

I have tried to sanity check most of them, mostly where I understood that the models returned are not what we hope the assistant to return, in which case I tried to experiment with rewriting the prompt a little bit to "nudge" the model in the right direction. Thi is not ideal, and in the longer term I will look into automatic query refining and rewriting.

The files with different prompts are named as `<file>_different.txt`

I could not find anything useful for T_S_Toxic with any kind of query rewriting.