# Local Execution

These experiments have been run using Llamafile + its built in OpenAI compliant server

Models in consideration are:

- Meta-Llama-3.1-8B-Instruct-Q4_K_S
- Meta-Llama-3.1-8B-Instruct-Q4_K_M
- Meta-Llama-3.1-8B-Instruct-Q5_K_S
- Meta-Llama-3.1-8B-Instruct-Q5_K_M
- Meta-Llama-3-8B-Instruct-Q4_K_S
- Meta-Llama-3-8B-Instruct-Q4_K_M
- Meta-Llama-3-8B-Instruct-Q5_K_S
- Meta-Llama-3-8B-Instruct-Q5_K_M


